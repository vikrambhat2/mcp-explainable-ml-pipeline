{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb539ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_groq import ChatGroq\n",
    "#llm = ChatGroq(\n",
    "#    model_name=\"qwen/qwen3-32b\",  #llama-3.3-70b-versatile\n",
    "#    temperature=0,\n",
    "#   api_key=os.getenv(\"GROQ_API_KEY\") \n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3d38b",
   "metadata": {},
   "source": [
    "# Initialize Ollama LLaMA 3.3 Model\n",
    "\n",
    "This snippet shows how to set up the Ollama LLaMA 3.3 language model using LangChain.\n",
    "\n",
    "It's a simple initialization that gets the model ready for generating text or handling chat-based tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d072c",
   "metadata": {},
   "source": [
    "\n",
    "### Setting Up MCP Client and Tools with LangGraph\n",
    "\n",
    "This example shows how to:\n",
    "\n",
    "- Configure an MCP client to connect to a server.\n",
    "- Load available tools from the MCP server.\n",
    "- Optionally preload specific domain resources.\n",
    "- Bind the loaded tools to a language model for use in conversations.\n",
    "\n",
    "Everything runs asynchronously, so you need to run it inside an async function or environment.\n",
    "\n",
    "This setup allows your language model to use external tools and data seamlessly during interactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d58baf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded resources: [Blob 4525021264]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Async setup in a function so we can use `await`\n",
    "\n",
    "# üß† MCP client config\n",
    "client = MultiServerMCPClient({\n",
    "    \"diabetes_server\": {\n",
    "        \"url\": \"http://localhost:8000/mcp\",\n",
    "        \"transport\": \"streamable_http\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# üõ†Ô∏è Load tools from MCP server\n",
    "mcp_tools = await client.get_tools()\n",
    "\n",
    "# üîç Optional: preload domain-specific resources\n",
    "resources = await client.get_resources(\"diabetes_server\", uris=[\"diabetes://guidelines/risk-factors\"])\n",
    "print(\"Loaded resources:\", resources)\n",
    "\n",
    "\n",
    "\n",
    "# üîó Model with prompt and tool binding\n",
    "model = llm.bind_tools(mcp_tools)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9de68",
   "metadata": {},
   "source": [
    "### LangGraph Chat Flow with Model and Tools\n",
    "\n",
    "This example shows how to build a simple chat flow using LangGraph:\n",
    "\n",
    "- The system sends user messages to a language model.\n",
    "- If the model requests external tools, those tools are called.\n",
    "- The results from the tools are sent back to the model.\n",
    "- This process repeats until no more tool calls are needed.\n",
    "\n",
    "The flow starts with the model generating a response and then decides whether to call tools or end the conversation.\n",
    "\n",
    "You can run queries through this chat flow asynchronously, and get dynamic, tool-enhanced answers from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Predict diabetes\n",
      "The prediction is 0, which means the model predicts that the individual does not have diabetes. The probability of this prediction is 0.31, which means there is a 31% chance that the individual does not have diabetes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LangGraph step functions\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build the LangGraph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"tools\", ToolNode(mcp_tools))  # Use ToolNode directly\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\"call_model\", should_continue, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# Run queries\n",
    "print(\"Query 1: Predict diabetes\")\n",
    "result = await graph.ainvoke({  # Use ainvoke for async execution\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Predict diabetes risk for age 45, BMI 28, pedigree 0.5\"}]\n",
    "})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22315b",
   "metadata": {},
   "source": [
    "\n",
    "### Running a Query Without Tool Invocation\n",
    "\n",
    "This example shows a question being asked where no external tools are triggered. The language model handles the response entirely on its own without invoking any tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dcc98de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insulin is a hormone produced by the pancreas that plays a crucial role in regulating blood sugar levels. It helps to facilitate the uptake of glucose by cells throughout the body, thereby lowering blood sugar levels. Insulin is essential for maintaining normal glucose metabolism and preventing conditions such as diabetes.\n",
      "\n",
      "In people with diabetes, the body either does not produce enough insulin (Type 1 diabetes) or is unable to effectively use the insulin it produces (Type 2 diabetes). As a result, blood sugar levels can become elevated, leading to a range of complications.\n",
      "\n",
      "Insulin therapy is often used to manage diabetes, particularly in people with Type 1 diabetes. There are several types of insulin, including:\n",
      "\n",
      "1. Rapid-acting insulin: Begins to work within 15-30 minutes and lasts for 2-4 hours.\n",
      "2. Short-acting insulin: Begins to work within 30-60 minutes and lasts for 4-6 hours.\n",
      "3. Intermediate-acting insulin: Begins to work within 1-2 hours and lasts for 12-18 hours.\n",
      "4. Long-acting insulin: Begins to work within 2-4 hours and lasts for 20-24 hours.\n",
      "\n",
      "Insulin can be administered via injection or an insulin pump, and it is typically prescribed by a healthcare provider as part of a comprehensive diabetes management plan.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"what is an insulin\"}]\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91749b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is a french population', additional_kwargs={}, response_metadata={}, id='58fa2bba-f94f-49fa-8cc6-797dcbf89b3e'),\n",
       "  AIMessage(content=\"The French population refers to the people who live in France, a country located in Western Europe. As of 2021, the estimated population of France is approximately 67.2 million people. The French population is diverse and includes people of various ethnic, cultural, and linguistic backgrounds.\\n\\nThe French population can be broken down into several categories, including:\\n\\n1. Native French: People who were born in France and have French ancestry.\\n2. Immigrant population: People who were born outside of France but have moved to the country, including those from European countries, Africa, Asia, and the Americas.\\n3. Overseas French: People who live in French overseas departments and territories, such as Guadeloupe, Martinique, and R√©union.\\n\\nThe French population is known for its rich cultural heritage, including its language, cuisine, art, and history. The country has a high standard of living, a well-developed economy, and a strong social safety net.\\n\\nSome key demographic characteristics of the French population include:\\n\\n* Age structure: The French population is aging, with a high proportion of people over the age of 65.\\n* Urbanization: The majority of the French population lives in urban areas, with the largest cities being Paris, Marseille, and Lyon.\\n* Education: Education is highly valued in France, and the country has a well-developed education system.\\n* Health: The French population has a high life expectancy and access to quality healthcare.\\n\\nOverall, the French population is a diverse and vibrant group of people who contribute to the country's rich cultural heritage and economic prosperity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 319, 'prompt_tokens': 307, 'total_tokens': 626, 'completion_time': 0.741085423, 'prompt_time': 0.015479727, 'queue_time': 0.090138032, 'total_time': 0.75656515}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--55e179f6-a6f9-4a2b-be60-a9fe6132b647-0', usage_metadata={'input_tokens': 307, 'output_tokens': 319, 'total_tokens': 626})]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
